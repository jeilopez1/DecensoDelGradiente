# -*- coding: utf-8 -*-
"""RegresionDecensoGradiente.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AW3skQHurW1GCmYDuerQcoc8rWIa8_XS
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_boston
from sklearn.preprocessing import StandardScaler

boston = load_boston()
XARRAY = np.array(boston.data[:, 5])
YARRAY = np.array(boston.target)
X = []
Y = []

for ix, x in enumerate(XARRAY):
    X.append(x)
for iy, y in enumerate(YARRAY):
    Y.append(y)

df = pd.DataFrame({"X": X, "Y": Y}, dtype="float64")

ss = StandardScaler()
df_transformed = ss.fit_transform(df)
x_transformed = df_transformed[:, 0]
y_transformed = df_transformed[:, 1]
X = x_transformed
Y = y_transformed

def func(a, b):
    respuesta = 0
    count = 0
    for xi, x in enumerate(X):
        count = count + 1
        respuesta = ((a + (b * x) - Y[xi]) ** 2) + respuesta
    return (1 / (2 * count)) * respuesta


res = 100

lineaA = np.linspace(-1, 1, res)
lineaB = np.linspace(-1, 1, res)

fig = plt.figure()
fig.tight_layout()

_Z = np.zeros((res, res))
count = 0

for ai, x in enumerate(lineaA):
    for ib, y in enumerate(lineaB):
        _Z[ib, ai] = func(x, y)


ramdomx = np.random.uniform(-1, 1)
ramdomy = np.random.uniform(-1, 1)
Theta = np.array([ramdomx, ramdomy])
ax2 = plt.subplot(1, 2, 2)
ax2.plot(Theta[0], Theta[1], c='blue', marker='o')

_T = np.copy(Theta)
h = 0.001
lr = 0.001

grad = np.zeros(2)

for _ in range(10000):
    for it, th in enumerate(Theta):
        _T = np.copy(Theta)
        _T[it] = _T[it] + h

        deriv = (func(_T[0], _T[1]) - func(Theta[0], Theta[1])) / h

        grad[it] = deriv

    Theta = Theta - lr * grad

    if _ % 500 == 0:
        ax2 = plt.subplot(1, 2, 2)
        ax2.contourf(lineaA, lineaB, _Z, res)
        ax2.plot(Theta[0], Theta[1], c='red', marker='.')
        ax = plt.subplot(1, 2, 1)
        """ax = plt.subplot(1, 1, 1)"""
        ax.plot([-3, 4], [Theta[0] + Theta[1] * -3, Theta[0] + Theta[1] * 4], c="red")
        ax.scatter(X, Y, alpha=0.3)
        ax.axis("equal")
        plt.draw()
        plt.pause(0.1)
        fig.clear()

ax2.plot(Theta[0], Theta[1], c='yellow', marker='o')

DatosNoEscalado = np.array([ss.inverse_transform([Theta[0], Theta[1]])[0], ss.inverse_transform([Theta[0], Theta[1]])[1]])


print(func(DatosNoEscalado[0], DatosNoEscalado[1])," <------ Solucion por metodo de escalado")
print(func(-34.670620776437374, 9.102108981180091),"<------ Resultado por minimos cuadrados")
ax = plt.subplot(1, 1, 1)
ax.scatter(X, Y, alpha=0.3)
ax.axis("equal")

ax.plot([-3, 4], [Theta[0] + Theta[1] * -3, Theta[0] + Theta[1] * 4], c="red")

plt.draw()
plt.pause(0.2)